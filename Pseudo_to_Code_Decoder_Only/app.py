import argparse
from pathlib import Path

import gradio as gr
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

from train_gpt2 import PROMPT_TEMPLATE


def build_generator(model_dir: Path, max_new_tokens: int, temperature: float, top_p: float):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    tokenizer = AutoTokenizer.from_pretrained(str(model_dir), use_fast=True)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    model = AutoModelForCausalLM.from_pretrained(str(model_dir)).to(device)
    model.eval()

    def generate_fn(pseudo_code: str) -> str:
        prompt = PROMPT_TEMPLATE.format(pseudo=pseudo_code.strip())
        inputs = tokenizer(prompt, return_tensors="pt").to(device)
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                do_sample=True,
                temperature=temperature,
                top_p=top_p,
                eos_token_id=tokenizer.eos_token_id,
            )
        gen_ids = outputs[0][inputs["input_ids"].shape[1]:]
        return tokenizer.decode(gen_ids, skip_special_tokens=True)

    return generate_fn


def main() -> None:
    parser = argparse.ArgumentParser(description="Gradio app for pseudo-code → Python code")
    parser.add_argument("--model_dir", type=str, required=True)
    parser.add_argument("--max_new_tokens", type=int, default=256)
    parser.add_argument("--temperature", type=float, default=0.2)
    parser.add_argument("--top_p", type=float, default=0.95)
    parser.add_argument("--server_port", type=int, default=7860)
    args = parser.parse_args()

    generate_fn = build_generator(Path(args.model_dir), args.max_new_tokens, args.temperature, args.top_p)

    with gr.Blocks(title="Pseudo-code → Python code (GPT-2)") as demo:
        gr.Markdown("""
        **Pseudo-code → Python code**\
        Enter structured pseudo-code and get Python code generated by a fine-tuned decoder-only model.
        """)
        with gr.Row():
            with gr.Column():
                inp = gr.Textbox(label="Pseudo-code", lines=10, placeholder="e.g., set x to 5; print x")
                btn = gr.Button("Generate")
            with gr.Column():
                out = gr.Code(label="Python code", language="python")
        btn.click(generate_fn, inputs=inp, outputs=out)

    demo.queue().launch(server_port=args.server_port)


if __name__ == "__main__":
    main()


